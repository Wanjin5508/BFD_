# Potential barriers on mobile devices
As with the introduction of almost *any new computer technology* the mobile phone introduced barriers to people with a disability in the beginning. Nowadays these devices can be very useful to them. In this step we introduce you to a few examples.

Information often is needed while being not at home nor in an office. Smartphones allow many activities, such as searching the web, orienting in unknown surroundings and last but not least to call someone if help is needed. Accessible mobile phones have changed the level of independence people with a disability can achieve. Examples: 

Carole ([_http://gpii.eu/moocap/?page_id=33_](http://gpii.eu/moocap/?page_id=33)) is blind and when working on a desktop computer she uses a regular keyboard, a headset and a braille display. Okay, laptops are portable and come with a keyboard, but placing phone calls and sending SMS through Skype is not very convenient when on the move. Many smartphones incorporate screen readers – it is part of the built in accessibility options. Carole **doesn't like wearing headsets while being outside**. She wants to **listen to the traffic** and hear the differences corners and bushes make when she taps with her long cane on the ground. She doesn’t mind other people are listening when she hears what the screenreader announces. The volume is just good enough when she holds the mobile phone close to her head. Carole’s first mobile phone had a keyboard, now she copes well with a phone just using a touch screen. The following steps show how Carole operates a screenreader on a mobile.

Mary ([http://gpii.eu/moocap/?page_id=54](http://gpii.eu/moocap/?page_id=54)) has arthritis and loves hands-free voice control and Siri-like assistants (speak commands and dictate comments) on her mobile phone. However, for her operating a touch screen is like wearing mittens and having to activate tiny buttons is a nightmare. When making a phone call outdoors, Mary places her phone on her lap while sitting or wedges it somewhere. She has disabled landscape mode and uses portrait mode only.

Mary takes notes by voice recording and assigns appointments via her calendar app. Synchronization with her office computer is very convenient – as it can be for most people. But navigation apps for pedestrians are not very good. In particular these apps don’t work indoors. Carole also struggles with some aspects of navigation when using mobile apps.  This is especially true when she encounters complex crossings, building works or there is no warning about an overhead branch. No navigation app helps the last 10 yards before she finds an entrance door.

# What Are You Using Your Smartphone For?

Besides taking to somebody or checking emails, mobile devices offer many possibilities of usage. Different sensors like GPS, compass, camera, WiFi, gyroscope, NFC are enabling apps to collect information from the environment. With those data, which can be processed locally or on a server, additional information, e.g. where to find an accessible entrance to a building, or when does the next bus arrive can be provided.

# Accessibility Features on Mobile Devices

Mobile phones and devices are an essential part of today’s live, empowering people to communicate with each other, to read, to work and to play. For people with disabilities the potential of such devices is huge – just think of **way finding applications** for blind people, or communication applications for nonverbal people. The question is now how people with disabilities are able to operate a mobile device, as most of the mobile devices today are operated with just a touchscreen and maybe one or two hardware buttons. At a first glance it seems impossible for some people of our personas, such as the blind Carole, to operate such a device.

However, today’s mainstream smartphones and mobile devices are shipped with a bunch of accessibility features built into the operating system that allow almost anybody to use such a device. In this step, we will give you a short overview on the accessibility feature available on today’s mobile devices grouped into 4 categories: v**ision**, **hearing**, **physical- and Motor-skills** and **cognitive** 

## Vision

### Screen Reader:

Today’s major operating systems for mobile devices like Android or iOS have a build in screen reader that allows blind people to operate the device with simple touches and gestures alone. **People can touch the screen to hear what’s under their finger**, can use **gestures** to explore the screen by manoeuvring from one element to the other and can activate elements with a screen using a double tab gesture. To get feedback on what is happening speech synthesis and vibrations are used. By this also blind people can operate a smartphone without any problems. A more in depth description about the functionalities of a screen reader will be given in the next step.

### Screen Magnifiers:

As the title says this function magnifies a part of the screen so that people with low vision like Maria can read the content of the screen. This tools offer different modes, either magnifying the whole screen or allowing the user to see a zoomed area in a separate window while keeping the rest of the screen at its native size.

![[Pasted image 20231112173242.png]]

### Speech Synthesis:

For people with low vision like Maria, this function allows users to select parts of the screen or the whole page and read it back to the user The user is able to adjust the voice’s dialect and speaking rate, and have words highlighted as they’re being read - making this a valuable tool for people who have problems to read content of the screen.

### Speech Recognition:

This function recognizes the voice of the user allowing converting the words and numbers into text that are entered in text fields and text areas. Besides that the user is also able to ask questions that the operating system tries to answer. The user is also able to send message, place phone calls, and schedule meetings with the use of his voice alone.

### Font Adjustments:

This function allows users like Maria to adjust the font size of the text that is displayed into a larger, easier to read size.

### Grayscale and Inverted Colours:

For people with colour vision deficiency like Alexander a higher contrast or a lack of colour helps the user to see better what’s on the display of the mobile device.
![[Pasted image 20231112173336.png]]

## Hearing:

### Video Call:

For deaf people like lars or heard of hearing people like Susan a video call can help them to understand the conversation as they can catch every gesture and facial expression. Also communication with sigh language is possible.

### Visible and Vibrating Alerts

Visual and vibrating alerts for incoming phone calls and messages are ideal for people who have problems to hear

## Physical- and Motor-Skills

## **Gesture Replacement**

People like Mary have **problems to perform certain gestures** like a pinch or a swipe gestures on the mobile device. These gestures can be replaced with other gestures that the user can perform, for example a single tab. By this most of the gestures to operate a mobile device can be replaced with personalized gestures that the user can perform. However there are limitations, especially when users have to drag an item to a certain location on the screen, can be complicated. 

## **Touch Configuration**

They can also configures whether repeated touches that are caused by a hand tremor should be ignored. People with physical disabilities can then put their finger anywhere on the screen and move to the item without mistakenly performing other actions.

## **Switch Access Scanning**

This technology allows people that are only able to operate one or more switches to operate mobile devices. Users can move sequentially over each item on the screen and when they want to perform an action on the item - like a touch on the icon - then they simply press the switch. This method allows the operation of very complex user interfaces by means of a single switch.
![[Pasted image 20231112173539.png]]

## Cognitive:

There are not too many build in tools available for people with cognitive disabilities that would help them to use a mobile device. If one assumes that people that suffer only from a cognitive disability they can perceive and operate the mobile device as people without cognitive disabilities. For them it’s sometimes difficult to focus on the application, to understand user interfaces or to read in general.

Here are some of the features that can be used:

-   Speech Recognition: To operate the mobile device and  to make calls
-   Speech Synthesis: For some people it’s easier to focus on the understanding of information and not also on reading
-   Touch Configuration: Therapists can disable certain buttons like the home button so that users do not press accidently the home and exit the app.


# Controlling a device in different ways

As people have **different disabilities** they use **different ways** of interacting with their mobile device. In this step we are going to show you some of the most **important input mehtods** for people with disabilities.

## Screenreader Control

Blind people use a special program to operate a mobile device. In this video Daniel Pöll gives a short introduction how he uses this tool.

-> Voice over: can read name of an app, then double tap the screen

## Braille Input

As you know already, some blind people are able to **read in Braille**. But they are also able to **type in Braille** using their mobile device. By this they are faster than typing on the classic on screen keyboard that the operating system offers.

![[Pasted image 20231112174220.png]]

## Switch Access Scanning

Switch Access Scanning is a Human-Computer-Interaction paradigm. With switch access scanning, people with physical disabilities who are **not able to operate a touch screen in the traditional way**, are still able to operate a mobile device. People can use **gestures**, like the *turning of the head, a hardware bluetooth switch* that they can press or even the whole touchscreen can act as a single switch. The focus of the application moves automatically from one element of the user interface to the next element. When the user wants to perform an action on the element, he just has to press the switch and the action is performed.
![[Pasted image 20231112180422.png]]

## Speech Input

Another way of interacting with a device is by speech input. The more the user trains the speech recognition software, the better he can control the device, as percentage of recognized words increases.

# Special Output Methods

Today's mobile devices provide a great variety of output mechanisms and lots of them are especially helpful in supporting people with disabilities. 

**Touch screen:** The touch screen is both the standard output and input device of a modern smart phone. It provides text and graphic output in a very high resolution and can also be adjusted to present that output with high contrast. Assistive software that is included in such smartphones can also be used to **magnify** text and graphics so that even people with a very low vision can read it. In the following video you can see how this screen magnification works:

Another advantage of touch screen input is that people with motor and mobility disabilities are able to increase the size of the controls on the screen (e.g. buttons) to make it easier for them to tap them. Older mobile devices with small buttons sometimes were hard to operate for these people. 

**Speech output and other sound feedback:** Since a long time, mobile devices provide the possibility to produce speech output, which is especially helpful for people with low or no vision. Assistive software, such as screen readers, provide information by speaking it over the devices built-in speakers or via headphones. Even people who do not demand a screen reader can use these speech output technologies, e.g. by selecting a longer piece of text on the screen and making the device read it to them. Even people with a normal level of vision use such technologies, for example to listen to a mail, SMS message or social networks status update while they are driving a car. 

**Braille devices:** Blind people also have the possibility to connect their Braille display to a mobile device, normally via a Bluetooth connection.

After doing so, a Braille device can receive information from the mobile device's assistive technologies (e.g. screen reader) and display virtually all information that can be read on the screen. Only graphics cannot be displayed on Braille displays, so most of the games which exist for mobile devices are not playable for blind users. However, any content that is text based can be displayed.

# Everyday activities of people with disabilities and the app ColourVisor

Colours help us to recognize all kind of objects in everyday life. For people who are blind this simple task is impossible to perform unless some assistive technology can support them. ColourVisor is an example of an app supporting everyday life activities. [The developer of this app, Jan Blüher, who is blind himself demonstrates and discusses its usefulness.](https://youtu.be/KuwNKWAK-1w)

![[Pasted image 20231112181236.png]]

# Multimedia on mobile devices

Mobile devices not only capture and present video and sound but allow also communication with someone else using multimedia. Examples:

A mobile phone can be a lifeline for people with a cognitive impairment. As an extreme example, talking with a friend has prevented some people from committing suicide. As a different example, people with aphasia organize their day and their life through a calendar or a task list. The many obligations to stay in contact with caregivers and keep appointments with social institutions are more easily fulfilled if reminders trigger the mobile phone owner through haptic or acoustic indicators.

Video conferencing is essential for signing among deaf people (e.g. Lars http://gpii.eu/moocap/?page_id=50). Smartphones quickly help to create such a session, as the camera’s autofocus handles all capturing. Both signers can watch themselves as long as the background provides sufficient contrast. More and more relay services provide a bridge between people who sign and people who speak and hear. Sign language interpreters can be called and they speak through another video conference session with someone who is hearing.

Special apps have been created for people going to the movies. A movie can be synchronized with audio descriptions as well as captions and streamed to a mobile phone to those who can benefit from it. No one else is disturbed and the extra effort for distribution is minimal since no specific technology is needed.

Smartphone are not always easy to handle. Audiobooks for visually impaired people (e.g. Maria http://gpii.eu/moocap/?page_id=42) are more popular on dedicated devices such as the Milestone (http://www.bones.ch/milestone112ace.php?Language=English). These devices have keys for input and control of audio is more straightforward than listening to a button label on a touch display. In particular navigation beyond change of audio tracks is well supported by the DAISY (http://www.daisy.org/daisypedia/daisy-digital-talking-book) book format. Practically all libraries for the blind produce DAISY titles nowadays and integrate either synthesized or recorded audio with structured text. Structured text allows going forward and backward in the audio book for example sentence by sentence, or paragraph by paragraph.

Tablets and smartphones are not only good for recording audio such as music or podcasts but also for editing these. Many audio editing apps on iOS and Android are accessible and it is easy to cut a track or operate a fader for control of volume. Even if the amount of data is considerable, WiFi allows the synchronizing of podcasts with repositories in the cloud without considering one’s cell phone plan.

Identifying podcasts and other multimedia contents becomes simple through iBeacons and QR-Codes. Finding the latter is not easy if vision is low, but tactile markings can help. People with low vision can handle many QR-code readers easily. Some apps are offering also optical character recognition (OCR) and thus picture taking has become an interesting type of activity for blind people (e.g. Carol http://gpii.eu/moocap/?page_id=35). A few apps such as the OptiAct series also recognize text on bank notes, cans and bottles and even can classify as well as name common objects in front of the camera.

# Outdoor navigation for people with disabilities - talk

Navigation is dependent on the user preferences and requirements for car drivers, cyclists, pedestrians and passengers in buses and trams. All of them can have different preferences. Elderly people often can’t walk that far. Mobility impaired users in a wheelchair or with a walking frame can’t climb stairs. Blind people with a guide dog can’t use an escalator. Furthermore indoor navigation in big buildings like an airport and train station has to be considered. [Gerhard Weber explains in the video also how an evaluation can be based on mental maps.](https://youtu.be/6UUjit9W9XY)


# WalkerGuide - outdoor navigation app for blind people

WalkerGuide ([http://walkersguide.org/en/](http://walkersguide.org/en/)) is a navigation app aiming at a novel service for **blind pedestrians**. It **calculates routes** for walking and considers also public transportation. The developer, [Eric Scheibler talks about his approach to provide step-by-step navigation and avoid busy roads and intersections.](https://youtu.be/bR-lbXweGs8) Being blind himself, he is familiar with other approaches to pedestrian navigation and has chosen **OpenStreetMap** as a source for **geographical data** but interprets them differently according to the needs of blind pedestrians.

# How can developers of new wearable technologies can be made aware of accessibility needs?

You have seen technology used with desktops can help to also make mobile technology more accessible. We have interviewed some developers who have a disability themselves and for whom accessibility is a natural requirement. 

The more specialized the mobile devices are, the more difficult it is to come up with accessible solutions from the beginning. Smart glasses, smart watches, electronic sports gear and even TV remote controls have not been made for people who have special sensory, physical of cognitive needs.

Please tell us what you think could help to make software and hardware developers more aware of the barriers they create.
